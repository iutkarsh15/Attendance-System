{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab803a9-3c60-406d-b786-8863c1f7ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "face_model = cv2.dnn.readNetFromTorch(\"models/openface.nn4.small2.v1.t7\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "dataset_path = \"known_faces\"\n",
    "\n",
    "for person_name in os.listdir(dataset_path):\n",
    "    person_folder = os.path.join(dataset_path, person_name)\n",
    "    if not os.path.isdir(person_folder):\n",
    "        continue\n",
    "    for image_name in os.listdir(person_folder):\n",
    "        image_path = os.path.join(person_folder, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        blob = cv2.dnn.blobFromImage(img, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "        face_model.setInput(blob)\n",
    "        vec = face_model.forward()\n",
    "        data.append(vec.flatten())\n",
    "        labels.append(person_name)\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels_num = le.fit_transform(labels)\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(data, labels_num)\n",
    "joblib.dump((clf, le), \"classifier.pkl\")\n",
    "print(\"Model trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a00d03b-e29a-4ea2-88c6-a7e0add61ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance system is only active between 9:30 AM and 10:00 AM.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "\n",
    "TEST_MODE = False\n",
    "\n",
    "face_model = cv2.dnn.readNetFromTorch(\"models/openface.nn4.small2.v1.t7\")\n",
    "face_detector = cv2.dnn.readNetFromCaffe(\"models/deploy.prototxt\", \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "age_net = cv2.dnn.readNetFromCaffe(\"models/age_deploy.prototxt\", \"models/age_net.caffemodel\")\n",
    "gender_net = cv2.dnn.readNetFromCaffe(\"models/gender_deploy.prototxt\", \"models/gender_net.caffemodel\")\n",
    "emotion_model = load_model(\"models/emotion_model.hdf5\", compile=False)\n",
    "\n",
    "age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "gender_list = ['Male', 'Female']\n",
    "emotion_list = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "dataset_path = \"known_faces\"\n",
    "names = []\n",
    "embeddings = []\n",
    "\n",
    "for person in os.listdir(dataset_path):\n",
    "    person_folder = os.path.join(dataset_path, person)\n",
    "    for image_name in os.listdir(person_folder):\n",
    "        image_path = os.path.join(person_folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        h, w = image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "        face_model.setInput(blob)\n",
    "        embedding = face_model.forward()\n",
    "        names.append(person)\n",
    "        embeddings.append(embedding.flatten())\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(names)\n",
    "\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "clf.fit(embeddings, labels)\n",
    "\n",
    "file_name = \"attendance.xlsx\"\n",
    "if not os.path.exists(file_name):\n",
    "    df = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\", \"Age\", \"Gender\", \"Emotion\", \"Status\"])\n",
    "    df.to_excel(file_name, index=False)\n",
    "\n",
    "def mark_attendance(name, age, gender, emotion):\n",
    "    now = datetime.datetime.now()\n",
    "    date_str = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "    df = pd.read_excel(file_name)\n",
    "    if not ((df[\"Name\"] == name) & (df[\"Date\"] == date_str)).any():\n",
    "        new_entry = {\"Name\": name, \"Date\": date_str, \"Time\": time_str, \"Age\": age, \"Gender\": gender, \"Emotion\": emotion, \"Status\": \"Present\"}\n",
    "        df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)\n",
    "        df.to_excel(file_name, index=False)\n",
    "\n",
    "def mark_absent_for_missing_students():\n",
    "    df = pd.read_excel(file_name)\n",
    "    date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    present_students = df[df[\"Date\"] == date_str][\"Name\"].unique()\n",
    "    all_students = os.listdir(dataset_path)\n",
    "    for student in all_students:\n",
    "        if student not in present_students:\n",
    "            now = datetime.datetime.now()\n",
    "            time_str = now.strftime(\"%H:%M:%S\")\n",
    "            absent_entry = {\"Name\": student, \"Date\": date_str, \"Time\": time_str, \"Age\": \"-\", \"Gender\": \"-\", \"Emotion\": \"-\", \"Status\": \"Absent\"}\n",
    "            df = pd.concat([df, pd.DataFrame([absent_entry])], ignore_index=True)\n",
    "    df.to_excel(file_name, index=False)\n",
    "\n",
    "current_time = datetime.datetime.now().time()\n",
    "start_time = datetime.time(9, 30)\n",
    "end_time = datetime.time(10, 0)\n",
    "\n",
    "if TEST_MODE or (start_time <= current_time <= end_time):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "        face_detector.setInput(blob)\n",
    "        detections = face_detector.forward()\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence < 0.6:\n",
    "                continue\n",
    "\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            x1, y1, x2, y2 = box.astype(\"int\")\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "            face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if face_img.size == 0:\n",
    "                continue\n",
    "\n",
    "            face_blob = cv2.dnn.blobFromImage(face_img, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "            face_model.setInput(face_blob)\n",
    "            embedding = face_model.forward().flatten().reshape(1, -1)\n",
    "            pred = clf.predict(embedding)[0]\n",
    "            name = le.inverse_transform([pred])[0]\n",
    "\n",
    "            face_blob2 = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), [104, 117, 123], swapRB=False)\n",
    "            gender_net.setInput(face_blob2)\n",
    "            gender = gender_list[gender_net.forward().argmax()]\n",
    "            age_net.setInput(face_blob2)\n",
    "            age = age_list[age_net.forward().argmax()]\n",
    "\n",
    "            gray_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "            resized_face = cv2.resize(gray_face, (64, 64))\n",
    "            resized_face = resized_face.astype(\"float32\") / 255.0\n",
    "            resized_face = np.expand_dims(resized_face, axis=0)\n",
    "            resized_face = np.expand_dims(resized_face, axis=-1)\n",
    "            emotion_preds = emotion_model.predict(resized_face, verbose=0)[0]\n",
    "            emotion = emotion_list[np.argmax(emotion_preds)]\n",
    "\n",
    "            mark_attendance(name, age, gender, emotion)\n",
    "\n",
    "            label = f\"{name}, {age}, {gender}, {emotion}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Attendance System\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if not TEST_MODE:\n",
    "        mark_absent_for_missing_students()\n",
    "else:\n",
    "    print(\"Attendance system is only active between 9:30 AM and 10:00 AM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18259247-cc6b-43ae-80be-c14ae8d52f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
